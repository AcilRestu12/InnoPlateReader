{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokumentasi :\n",
    "- Train : https://docs.ultralytics.com/modes/train/\n",
    "- Metrics : https://docs.ultralytics.com/reference/utils/metrics/#ultralytics.utils.metrics.ConfusionMatrix.matrix\n",
    "- Performance Metrics : https://docs.ultralytics.com/guides/yolo-performance-metrics/#conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"D:/Coding/Projects/number-plate-recognition/model/best.pt\")  # build a new model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.239 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.202  Python-3.9.7 torch-2.1.0+cu121 CPU (AMD Ryzen 7 3750H with Radeon Vega Mobile Gfx)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=D:/Coding/Projects/number-plate-recognition/model/best.pt, data=D:/Coding/Projects/number-plate-recognition/static/config.yaml, epochs=1, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=0, project=D:/Coding/Projects/number-plate-recognition/base_model, name=testing5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=D:\\Coding\\Projects\\number-plate-recognition\\base_model\\testing5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir D:\\Coding\\Projects\\number-plate-recognition\\base_model\\testing5', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Coding\\Projects\\number-plate-recognition\\static\\labels\\train.cache... 0 images, 8 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<?, ?it/s]\n",
      "WARNING  No labels found in D:\\Coding\\Projects\\number-plate-recognition\\static\\labels\\train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Coding\\Projects\\number-plate-recognition\\static\\labels\\train.cache... 0 images, 8 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<?, ?it/s]\n",
      "WARNING  No labels found in D:\\Coding\\Projects\\number-plate-recognition\\static\\labels\\train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n",
      "Plotting labels to D:\\Coding\\Projects\\number-plate-recognition\\base_model\\testing5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Coding\\Projects\\number-plate-recognition\\base_model\\testing5\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/1         0G          0      43.64          0          0        640: 100%|██████████| 1/1 [00:08<00:00,  8.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n",
      "                   all          8          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "1 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from D:\\Coding\\Projects\\number-plate-recognition\\base_model\\testing5\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from D:\\Coding\\Projects\\number-plate-recognition\\base_model\\testing5\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating D:\\Coding\\Projects\\number-plate-recognition\\base_model\\testing5\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.202  Python-3.9.7 torch-2.1.0+cu121 CPU (AMD Ryzen 7 3750H with Radeon Vega Mobile Gfx)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "                   all          8          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n",
      "Speed: 3.0ms preprocess, 181.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Coding\\Projects\\number-plate-recognition\\base_model\\testing5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " status : start\n",
      "Error: 'DetMetrics' object has no attribute 'curves_results'. See valid attributes below.\n",
      "\n",
      "    This class is a utility class for computing detection metrics such as precision, recall, and mean average precision\n",
      "    (mAP) of an object detection model.\n",
      "\n",
      "    Args:\n",
      "        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n",
      "        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n",
      "        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n",
      "        names (tuple of str): A tuple of strings that represents the names of the classes. Defaults to an empty tuple.\n",
      "\n",
      "    Attributes:\n",
      "        save_dir (Path): A path to the directory where the output plots will be saved.\n",
      "        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n",
      "        on_plot (func): An optional callback to pass plots path and data when they are rendered.\n",
      "        names (tuple of str): A tuple of strings that represents the names of the classes.\n",
      "        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n",
      "        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n",
      "\n",
      "    Methods:\n",
      "        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n",
      "        keys: Returns a list of keys for accessing the computed detection metrics.\n",
      "        mean_results: Returns a list of mean values for the computed detection metrics.\n",
      "        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n",
      "        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n",
      "        fitness: Computes the fitness score based on the computed detection metrics.\n",
      "        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n",
      "        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n",
      "        curves: TODO\n",
      "        curves_results: TODO\n",
      "    \n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Train model (use data part 1-7 & addition 1 & addition 2 & addition 3) (8th Testing)\n",
    "result = None\n",
    "status = 'start'\n",
    "error_message = None\n",
    "result = model.train(data=\"D:/Coding/Projects/number-plate-recognition/static/config.yaml\", epochs=1, \n",
    "                     project=\"D:/Coding/Projects/number-plate-recognition/base_model\", name=\"testing\")  # train the model\n",
    "try:\n",
    "    print(result)\n",
    "except AttributeError as ae:\n",
    "    status = 'start'\n",
    "    error_message = f\"Error: {str(ae)}\"\n",
    "    print(f'\\n status : {status}')\n",
    "    print(error_message)\n",
    "    print('------------')\n",
    "except Exception as e:\n",
    "    error_message = f\"Error: {str(e)}\"\n",
    "    print(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DetMetrics' object has no attribute 'curves_results'. See valid attributes below.\n\n    This class is a utility class for computing detection metrics such as precision, recall, and mean average precision\n    (mAP) of an object detection model.\n\n    Args:\n        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n        names (tuple of str): A tuple of strings that represents the names of the classes. Defaults to an empty tuple.\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered.\n        names (tuple of str): A tuple of strings that represents the names of the classes.\n        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n\n    Methods:\n        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n        keys: Returns a list of keys for accessing the computed detection metrics.\n        mean_results: Returns a list of mean values for the computed detection metrics.\n        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n        fitness: Computes the fitness score based on the computed detection metrics.\n        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n        curves: TODO\n        curves_results: TODO\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Coding\\Projects\\number-plate-recognition\\env\\lib\\site-packages\\ultralytics\\utils\\__init__.py:136\u001b[0m, in \u001b[0;36mSimpleClass.__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m attr \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 136\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m a\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, SimpleClass):\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;66;03m# Display only the module and class name for subclasses\u001b[39;00m\n",
      "File \u001b[1;32md:\\Coding\\Projects\\number-plate-recognition\\env\\lib\\site-packages\\ultralytics\\utils\\__init__.py:153\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[0;32m    152\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DetMetrics' object has no attribute 'curves_results'. See valid attributes below.\n\n    This class is a utility class for computing detection metrics such as precision, recall, and mean average precision\n    (mAP) of an object detection model.\n\n    Args:\n        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n        names (tuple of str): A tuple of strings that represents the names of the classes. Defaults to an empty tuple.\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered.\n        names (tuple of str): A tuple of strings that represents the names of the classes.\n        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n\n    Methods:\n        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n        keys: Returns a list of keys for accessing the computed detection metrics.\n        mean_results: Returns a list of mean values for the computed detection metrics.\n        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n        fitness: Computes the fitness score based on the computed detection metrics.\n        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n        curves: TODO\n        curves_results: TODO\n    "
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_plot = result.confusion_matrix.plot(normalize=False, save_dir=\"D:/Coding/Projects/New folder/number-plate-recognition/base_model/testing_4/result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = result.confusion_matrix.matrix\n",
    "tp = cf[0][0]\n",
    "fp = cf[0][1]\n",
    "fn = cf[1][0]\n",
    "tn = cf[1][1]\n",
    "accuracy = (tp + tn) / (tp+fp+fn+tn)\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp /(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val()  # evaluate model performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix.plot(normalize=False, save_dir=\"D:/Coding/Projects/New folder/number-plate-recognition/base_model/testing_432/result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_predict = model(\"D:/Coding/Projects/New Folder/number-plate-recognition/data/K1_G6853EQ.jpg\")  # predict on an image\n",
    "# path = model.export(format=\"pt\")  # export the model to ONNX format\n",
    "# path = model.export(format=\"torchscript\")  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on 'bus.jpg' with arguments\n",
    "results = model.predict(\"D:/Coding/Projects/number-plate-recognition/data/K1_G6853EQ.jpg\", save=True, imgsz=320, conf=0.1)\n",
    "# results = model('bus.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    print(r.boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg', 'txt'])\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "           \n",
    "a = allowed_file(\"K1_AA2503XT.JPG\")\n",
    "a\n",
    "\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_extension(file_name):\n",
    "    try:\n",
    "        file_extension = file_name.split('.')[-1]\n",
    "        return file_extension.lower() \n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "# Contoh penggunaan:\n",
    "file_name = \"K1_AA2503XT.JPG\"\n",
    "extension = get_file_extension(file_name)\n",
    "print(f\"The file extension of {file_name} is: {extension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 20\n",
    "confidence = confidence / 100\n",
    "confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = 'PNG'\n",
    "# ext = ext.lower()\n",
    "if ext.lower() in ['png', 'jpg', 'jpeg']:\n",
    "    print(ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 5, 7\n",
    "print(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
