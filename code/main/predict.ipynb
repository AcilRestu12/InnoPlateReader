{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"d:/Coding/Projects/number-plate-recognition/runs/detect/train17/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'save_crop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Coding\\Projects\\number-plate-recognition\\code\\main\\predict.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Coding/Projects/number-plate-recognition/code/main/predict.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results\u001b[39m.\u001b[39;49msave_crop()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'save_crop'"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "path_image = \"D:/Coding/Projects/number-plate-recognition/data/K1_G6853EQ.jpg\"\n",
    "img = cv2.imread(path_image)\n",
    "img_size = img.shape[0:2]\n",
    "\n",
    "# Predict plat\n",
    "results = model()[0]\n",
    "\n",
    "# Draw rectangle\n",
    "for result in results.boxes.data.tolist():\n",
    "    x1, y1, x2, y2, score, class_id = result\n",
    "    cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "    cv2.putText(img, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "# Show image\n",
    "# cv2.namedWindow('image', cv2.WINDOW_NORMAL)  # WINDOW_NORMAL memungkinkan pengubahan ukuran jendela\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# cv2.imshow('image', img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([])\n",
      "conf: tensor([])\n",
      "data: tensor([], size=(0, 6))\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (4000, 2252)\n",
      "shape: torch.Size([0, 6])\n",
      "xywh: tensor([], size=(0, 4))\n",
      "xywhn: tensor([], size=(0, 4))\n",
      "xyxy: tensor([], size=(0, 4))\n",
      "xyxyn: tensor([], size=(0, 4))\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "for r in results:\n",
    "    print(r.boxes)  # print the Boxes object containing the detection bounding boxes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
